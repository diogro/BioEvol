---
title: "Tutorial Biologia Evolutiva 2017"
author: "Diogo Melo"
date: "October 12, 2017"
output:
  html_document:
    highlight: tango
    number_sections: yes
    theme: flatly
    toc: yes
    toc_float:
      collapsed: no
      smooth_scroll: no
  pdf_document:
    toc: yes
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Introdução

Primeiro alguns links:

- [Roteiro para elaboração da monografia final](http://diogro.github.io/BioEvol/roteiro.html)
- [Apostila da disciplina](https://github.com/lem-usp/apostila-bio-evol/blob/master/apostila-Bio312.pdf?raw=true)

## Genética quantitativa e evolução

Neste tutorial vamos passar por todas as etapas de análise de um conjunto de dados em genética quantitativa aplicada à macroevolução. Vamos estudar quatro caracteres quantitativos medidos em cinco espécies de roedores em uma filogenia conhecida. Usando esse conjunto de dados, vamos caracterizar o padrão de modularidade em cada espécie, as diferenças nas morfologias médias, e os processos evolutivos que levaram à diferenciação atual.

O primeiro passo, como sempre, é escolher um ambiente de análise. Neste tutorial vamos usar a linguem R, mas todos os passos poderiam ser feitos num programa gráfico como excel e Systat, ou em qualquer outra linguagem de programação, como python, perl, java, C ou Haskell. A linguagem R é especialmente conveniente, primeiro por que os monitores sabem usar ela, e segundo por que existe um pacote (escrito pelos monitores) que automatiza várias dos passos da análise.

## A linguagem R

R é um ambiente de programação _open source_ criado pensando em análises estátisticas. Você pode ler um pouco mais sobre a linguagem neste [site](http://ecologia.ib.usp.br/bie5782/doku.php?id=bie5782:03_apostila:01-intro}).

### Instalando o R

Se você está utilizando um dos computadores do IB, o R já deve estar instalado. Se não, siga as instruções nesse [site](https://mran.revolutionanalytics.com/download/) para instalar o R, e opcionalmente (mas muito recomendado!) o editor de código [RStudio](https://www.rstudio.com/products/rstudio/download/).

### Rodando comandos

Ao longo desse tutorial, você sempre vai ver blocos de código que devem ser executados no ambiente R. Por exemplo, se estivessemos interessados em somar dois números poderiamos digitar:

```{r sum}
1 + 1
```

E abaixo da operação temos o resultado que o programa retorna. 

Você pode também associar valores a variáveis (chamados objetos) e utilizar esses objetos nas suas operações. O operador "=" associa um valor a um objeto:

```{r objects}
x = 1
y = 2
x + y
```
  
## Seguindo o tutorial

Exitem dois jeitos de seguir esse tutorial: (1) cegamente copiar e colar os comandos no R ver o resultado; ou (2) entender o que cada parte do comando executado está fazendo e assim já aprender um pouco de R de brinde. Ambas são ok! Nosso objetivo aqui é a biologia evolutiva, o R é só um acessório. Quando alguma operação no R parecer mais esotérica, vamos tentar explicar nos comentários do código ou no texto. Se não ficar claro, consulte os monitores!

## Preliminares

Para começar, precisamos instalar um pacote (chamado evolqg) e carregar os dados para a area de trabalho usando a função data. Funções no R são como pequenos conjuntos de instruções com um nome. Para executar uma função basta digitar o nome dela, com os argumentos daquela função entre parênteses. Linhas que começam com # são comentários e são ignoradas pelo R. (Para ver mais exemplos iniciais, confira [esse tutorial](http://ecologia.ib.usp.br/bie5782/doku.php?id=bie5782:03_apostila:02-entrada) do curso de pós-graduação em R oferecido pela ecologia do IB!)

```{r packagesfake, eval = FALSE}
# Instalando o pacote de genética quantitativa evolutiva
if(!require(evolqg)){install.packages("evolqg")}

# Carregando o pacote evolqg
library(evolqg)

# Carregando o conjunto de dados que vamos utilizar
data(dentus)
```
```{r packages, echo = FALSE}
library(evolqg)
data(dentus)
```

## Aos dados!

Com os dados carregados, podemos ver todas as medidas digitando o nome do objeto com os dados. 

Aqui vamos ver só as primeiras linhas, mas no seu computador você deve ver o conjunto completo.

```{r fake, eval = FALSE}
dentus
```
```{r dados, echo = FALSE}
head(dentus)
```

Como podemos ver, os dados estão organizados em linhas e colunas. Cada linha representa um indivíduo, e cada coluna representa um caráter. As 4 primeiras colunas são os caracteres quantitativos, e a quinta coluna contém a espécie de cada indivíduo.

Essa mesma planilha está disponível nesse [link](https://raw.githubusercontent.com/diogro/BioEvol/master/dentus2016.csv).

# Objetivos da Aula 1

Em cada aula vamos fazer algumas contas e discutir os resultados. Ao final do curso todos esses resultados devem ser compilado num relatório final.

Nessa aula vamos calcular:

1. Média de cada caráter;
2. Variância de cada caráter;
3. Coeficiente de variação de cada caráter;
2. Gráfico da distribuição de cada caráter.

## Médias e variâncias globais

Vamos começar calculando as médias globais utilizando a função sapply e a função mean. 

Os resultados não aparecem aqui, mas rodando os comandos no R você deve ser capaz de produzí-los!

```{r, eval = FALSE}
# Como a última coluna contém as espécie, 
# vamos utilizar o operador de indexação do R  [] para selecionar as colunas de 1 a 4.
# A função sapply passa todas as colunas do primeiro argumento para a função no segundo argumento. 
sapply(dentus[,1:4], mean)
```

Podemos utilizar a mesma estratégia para calcular as variâncias e desvios padrões:

```{r, eval = FALSE}
# Variâncias
sapply(dentus[,1:4], var)

# Desvios padrão
sapply(dentus[,1:4], sd)
```

Para calcular o coeficiente de variação, podemos dividir diretamente o desvio padrão pela média:

```{r, eval = FALSE}
# Objeto com os desvios padrão
dentus_sd = sapply(dentus[,1:4], sd)

# Objeto com as médias
dentus_mean = sapply(dentus[,1:4], mean)

# Cálculo do coeficiente de variação
dentus_sd/dentus_mean
```

Ou podemos criar uma função que calcula o coeficiente de variação diretamente

```{r, eval = FALSE}
# Função que calcula o coeficiente de variação
cv = function(x) sd(x)/mean(x)

# Coeficiente de variação
sapply(dentus[,1:4], cv)
```

## Médias e variâncias por espécie

Agora vamos tentar obter esses mesmos valores separando os dados pos espécie. A função aggregate vai ajudar. Essa função é muito semelhante à sapply, mas ela recebe um argumento adicional que permite utilizar uma coluna dos dados para separar os individuos em grupos. Por exemplo, para calcular a média por espécie fazemos:

```{r}
aggregate(dentus[,1:4], list(especie = dentus[,5]), mean)
```

Vc consegue seguir essa lógica e calcular as variâncias e coeficientes de variação por espécie?

## Gráficos

É sempre importantissimo visualisar os dados usando gráficos antes de fazer qualquer análise mais complexa. Vamos explorar várias possibilidades de gráficos que revelam aspectos diferentes da distribuição dos nossos dados. 

Para isso vamos carregar alguns pacotes gráficos:

### Carregando pacotes gráficos

```{r, eval = FALSE}
list_pkgs <- c("ggplot2", "GGally", "reshape2")
new_pkgs <- list_pkgs[!(list_pkgs %in% installed.packages()[,"Package"])]
if(length(new_pkgs) > 0){ install.packages(new_pkgs) }

library(evolqg)
library(ggplot2)
library(GGally)
library(reshape2)
```

### Gráficos univariados

O primeiro e mais simples talvez seja o histograma.

```{r, eval = FALSE}
ggplot(melt(dentus), aes(value, group = species, fill = species)) + 
  geom_histogram() + 
  facet_wrap(~variable, scale = "free")
```

Podemos também usar boxplots:

```{r, eval = FALSE}
ggplot(melt(dentus), aes(species, value, fill = species, group = interaction(species, variable))) + 
  geom_boxplot() + 
  facet_wrap(~variable, scale = "free")
```

Ou um chiquérrimo violin plot:

```{r, eval = FALSE}
ggplot(melt(dentus), aes(species, value, fill = species, group = interaction(species, variable))) + 
  geom_violin() + 
  facet_wrap(~variable, scale = "free")
```

### Gráficos bivariados

Outro aspecto interessante é a relação par a par das variáveis.

Por exemplo, vamos olhar para a distribuição bivariada dos dois primeiros caracteres, incluindo também uma reta de regressão por espécie:

```{r, eval = FALSE}
ggplot(dentus, aes(humerus, ulna, group = species, color = species)) + 
  geom_point() +
  geom_smooth(method = "lm", aes(group = species))
```

Vc poderia fazer esse gráfico manualmente para todos os pares de caracteres, mas a função ggpairs resume tudo isso de uma vez:

```{r, eval = FALSE}
ggpairs(dentus, mapping = aes(color = species), 
        columns = c("humerus", "ulna","femur", "tibia"))
```

# Leitura da Aula 2

- [The Ecological Significance of Correlation Pleiades](https://www.jstor.org/stable/2405824) ([pdf](https://github.com/lem-usp/site-bio208/raw/master/static/pdfs/artigos/Berg-1960.pdf))

    __Abstract:__
    The phenomenon of correlation pleiades, i.e., the presence of correlations between some quantitative characteristics of certain parts of an organism and at the same time by the absence of correlations between these and the other parts demonstrates the independence of certain developmental processes with respect to other processes within the organism. The study of correlation sets makes it possible to establish the degree of such independence. The adoption of a quantitative criterion provides an adequate basis for the comparative method in the study of stabilizing selection. Nineteen species of herbaceous plants have been studied in order to determine the variability in the degree of dependence between the dimensions of different parts of an organism. It has been established that twelve species have correlation pleiades, while seven species have no correlation pleiades with respect to the dimensions of analogous parts. In all the instances of existence of pleiades it was the flower that had become free of the correlation interdependences within the plant organism. Existence of correlation pleiades is associated with the mode of pollen transfer, involving the presence of specific insect pollinators, with adaptations to localize the pollen deposit on some definite part of the body of the pollinating insect, and with at least one of the structural features providing for such localization (zygomorphism, presence of tubular parts, lateral position of flowers, oligomerization and a rigid fixation of the number of homologous parts of a flower). Insects were the selective factor stabilizing the dimensions of those parts of flowers which participate in the process of the precise localization of pollen on the insect body. Stabilizing selection of flower dimensions created correlation pleiades for reproductive organs, as well as for vegetative parts of the same organism. The general principle underlying the origin of developmental homeostasis in the process of evolution is the discrepancy between the agencies participating in the formation of the character and the selective forces determining its function. The same principle is responsible for the origin of correlation pleiades.

# Objetivos da Aula 2

Nessa aula vamos explorar a associação presente entre os caracteres fenotípicos nas nossas populações.
Com isso vamos poder discutir questões ligadas a função, desenvolvimento e a interação das populações com a seleção natural.

Para isso, vamos calcular:

 1. A matriz de covariância fenotípica total;
 2. A matriz de covariância fenotípica por espécie;
 3. A matriz de correlação por espécie;

Além disso, discuta:

 1. Qual o padrão modular de cada espécie?
 2. Qual é a intensidade da associação entre os caracteres em cada espécie?

## Covariâncias e correlações

Para entender como a associação entre os caracteres muda entre espécies, é preciso quantificá-la. Para isso, vamos utilizar os conceitos de covariância e correlação. A covariância entre duas variáveis é definida como a média do produto dos desvios das médias das variáveis. Ou seja, se $\overline x$ e $\overline y$ são as médias dos caracteres $x$ e $y$, a covariâncias entre eles numa população é:

$$
Cov(x, y) = \frac{1}{N} \sum_{i = 1}^{N} (x_i - \overline{x})(y_i - \overline y)
$$

Para que possamos entender essa formula intuitivamente, vamos pensar nos sinais de cada termo da soma. Em que condições o termo $(x_i - \overline{x})(y_i - \overline y)$ é positivo e contribui pra aumentar a covariância? E quando ele é negativo? Como esse termo é um produto de desvios, o produto vai ser positivo quando os dois desvios tiverem o mesmo sinal, e negativo quando os desvios tiverem sinais diferentes. Ou seja: quando tanto o caráter $x$  quando o $y$ estiverem acima ou abaixo das suas médias, o produto é positivo e contribui pra aumentar a covariância; quando $x$ é menor do que a média e $y$ é maior, ou vice-versa, o produto é negativo e contribui para diminuir a covariância. Se, ainda, os desvios não tiverem relação nenhuma, desvios na mesma direção e em direções opostas tendem a se cancelar, e a covariação será
próxima de zero. Isso está ilustrado na figura abaixo, indivíduos nas regiões em azul aumentam a covariância, enquanto indivíduos na região em amarelo diminuem a covariância.

```{r, echo = FALSE, warning=FALSE, message=FALSE }
set.seed(42)
library(ggplot2)
library(mvtnorm)
data = data.frame(rmvnorm(50, sigma = 0.8*matrix(c(1, 0.7, 0.7, 1), 2)))
ggplot(data, aes(X1, X2)) +
   annotate("rect", xmin = Inf, xmax = 0, ymin = Inf, ymax = 0, fill= "blue", alpha = 0.5)  +
   annotate("rect", xmin = -Inf, xmax = 0, ymin = -Inf, ymax = 0 , fill= "blue", alpha = 0.5) +
   annotate("rect", xmin = 0, xmax = Inf, ymin = 0, ymax = -Inf, fill= "yellow", alpha = 0.5) +
   annotate("rect", xmin = 0, xmax = -Inf, ymin = Inf, ymax = 0, fill= "yellow", alpha = 0.5) +
   geom_point() + theme_classic() + xlim(-2,2)+ ylim(-2,2) + labs(x = "x", y = "y")
```

As covariâncias entre caracteres são quantidades muito importantes na biologia evolutiva, como vamos ver mais adiante no curso. Apesar disso, elas sofrem do mesmo problema das variâncias: dependem da escala absoluta dos caracteres sendo medidos. Assim, não podemos comparar covariâncias entre pares de caracteres que tenham escalas diferentes, e não podemos comparar as covariâncias entre os mesmo caracteres medidos em organismos que tenham escalas diferentes. Para isso, vamos definir uma segunda medida de associação que e admensional, e que pode ser comparada entre escalas: a correlação linear. Note que se medirmos a covariância de um caráter com ele mesmo, chegamos na formula da variância. A partir disso, é fácil mostrar que o valor mais alto que uma covariância pode assumir é o produto dos desvios padrão entre as variâveis medidas (afinal, a covariância máxima de um caráter é com ele mesmo, ou seja, sua variância, que é o desvio padrão ao quadrado). Então, vamos definir a correlação como a proporção da covariância máxima entre dois caracteres, ou a covariância dividido pelo produto dos desvios padrão:

$$
Cor(x, y) = \frac{Cov(x, y)}{\sigma_x \sigma_y} = \frac{1}{N} \sum_{i = 1}^{N} \frac{(x_i - \overline{x})(y_i - \overline y)}{\sigma_x \sigma_y}
$$

Essa quantidade varia entre -1 e 1, e mede o grau de associação entre duas variáveis numa escala absoluta. Correlações próximas de 1 indicam que os caracteres variam juntos e na mesma direção; correlações próximas de -1 indicam que os caracteres variam juntos mas em direções opostas; correlações próximas de zero indicam que os caracteres são independentes. A correlação pode ser comparada entre caracteres e populações diferentes.

## Medindo covariâncias e correlações no R

Primeiro vamos carregar os dados novamente:

```{r}
# Carregando o pacote evolqg
if(!require(evolqg)){install.packages("evolqg"); library(evolqg)}
data(dentus)
```

Agora vamos utilizar a função cov para calcular a covariância entre um par de caracteres:

```{r}
cov(dentus$humerus, dentus$ulna)
```

__Pergunta__: Esse valor de covariância é alto ou baixo?

__Resposta__: Não faço a mais parva ideia! A covariância depende da escala! Vamos olhar para a correlação (usando a função cor), que tem escala absoluta.

```{r}
cor(dentus$humerus, dentus$ulna)
```

Esse é um valor próximo de 1, indicando alta associação entre as duas variáveis. Podemos ver isso num gráfico bivariado:

```{r, warning=FALSE, message=FALSE }
set.seed(42)
library(ggplot2)
library(mvtnorm)
ggplot(dentus, aes(humerus, ulna)) +
   annotate("rect", xmin = Inf, xmax = mean(dentus$humerus),
            ymin = Inf, ymax = mean(dentus$ulna), fill= "blue", alpha = 0.5)  +
   annotate("rect", xmin = -Inf, xmax = mean(dentus$humerus),
            ymin = -Inf, ymax = mean(dentus$ulna) , fill= "blue", alpha = 0.5) +
   annotate("rect", xmin = mean(dentus$humerus), xmax = Inf,
            ymin = mean(dentus$ulna), ymax = -Inf, fill= "yellow", alpha = 0.5) +
   annotate("rect", xmin = mean(dentus$humerus), xmax = -Inf,
            ymin = Inf, ymax = mean(dentus$ulna), fill= "yellow", alpha = 0.5) +
   geom_point() + theme_classic()
```

A grande maioria dos pontos fica na região azul.

## Medindo várias covariâncias no R

Para que possamos comparar e interpretar a covariância ou correlação entre vários pares de caracteres simultaneamente, vamos utilizar uma notação matricial. Numa matriz de variância-covariância (ou simplesmente matriz de covariância), podemos representar todos os caracteres nas linhas e colunas, e assim, para saber a covariância entre um par de caracteres basta consultar a linha correspondente ao primeiro caráter na coluna correspondente ao segundo caráter. Para um conjunto de $p$ caracteres $\{z_1, z_2, ..., z_p\}$, podemos excrever sua matriz de covariância como:

$$
\begin{matrix}
Var(z_1) & Cov(z_1, z_2) & \cdots & Cov(z_1, z_p) \\
Cov(z_1, z_2) & Var(z_2) & \cdots & Cov(z_2, z_p) \\
\vdots & \vdots  & \ddots & \vdots                \\
Cov(z_1, z_p) & Cov(z_1, z_p) & \cdots & Var(z_p) \\
\end{matrix}
$$

No R, basta chamar a função cov num objeto com mais de uma coluna:

```{r}
cov(dentus[,1:4])
```

Essa é a matriz de covariância total (sem separação por espécie) dos nossos dados. Onde está o valor de covariância entre humero e ulna que calculamos antes? Esse valor aparece quantas vezes na matriz? Por que? Você consegue calcular agora a matriz de correlação total? Tem um jeito fácil (função cor), um médio (função cov2cor), e um difícil (na unha)!

## Medindo covariâncias de cada espécie

Agora vamos medir as covariâncias e correlações dentro de cada espécie. Para isso, vamos aprender a escolher apenas algumas linhas de uma tabela de dados no R. Suponha que eu queira ver apenas as linhas que sejam da espécie A. Posso fazer isso com o comando:

```{r, eval = FALSE}
dentus[ dentus$species == "A", ]
```

Podemos agora usar esse conjunto de dados reduzido para calcular a matriz da espécie A, e armazenar a matriz num objeto chamado cov_A:

```{r}
(cov_A = cov(dentus[ dentus$species == "A", 1:4]))
```

Siga essa mesma lógica e crie objetos para as matrizes de covariância e correlação de todas as espécies.

## Visualizando correlações

Podemos utilizar as matrizes de correlação para fazer representações gráficas da relação entre os pares de caracteres. Vamos escrever uma função (admito que meio complicada) que faça isso:

```{r, message=FALSE}
library(ggplot2)
library(reshape2)
if(!require(viridis)) install.packages("viridis")
library(viridis)
plotMatrix <- function (corMat, file = NULL) {
  diag(corMat) <- NA
  n_traits = nrow(corMat)
  myPalette <- viridis(50)
  ## Se quiser uma paleta All American, use essa linha em vez da anterior
  #myPalette <- colorRampPalette(c("blue", "white", "red"))(n = 50)
  m.rs = melt(corMat)
  m.rs$Var1 <- factor(m.rs$Var1, levels = m.rs$Var1[n_traits:1])
  m.rs.position = m.rs
  m.rs.position$Var1 <- as.numeric(m.rs.position$Var1)
  m.rs.position$Var2 <- as.numeric(m.rs.position$Var2)
  m.rs.position$value= round(m.rs.position$value, 2)
  m.rs.position$value[is.na(m.rs.position$value)] <- levels(m.rs$Var1)[n_traits:1]
  p <-
    ggplot (m.rs) +
    geom_tile(aes(x = Var2, y = Var1, fill = value)) +
    scale_fill_gradientn(name = '', colours = myPalette, limits = c(-0.15, 1)) +
    labs(x = NULL, y = NULL) +
    geom_text(data = m.rs.position, aes(x = Var2, y = Var1, label = value)) +
    theme_bw()
  if(!is.null(file)) cowplot::save_plot(plot = p, file)
  return(p)
}
```

Agora podemos usar essa função para plotar a matriz de correlação de uma das espécies:

```{r}
cor_A = cor(dentus[ dentus$species == "A", 1:4])
plotMatrix(cor_A)
```

Olhe para todas as matrizes de correlação. Quais são os padrões modulares? Como esses padrões diferem entre as espécies?

# Leitura da Aula 3

- [The Evolution of Modularity in the Mammalian Skull I: Morphological Integration Patterns and Magnitudes](https://link.springer.com/article/10.1007/s11692-008-9038-3) ([pdf](https://github.com/lem-usp/site-bio208/raw/master/static/pdfs/artigos/Porto%20et%20al.%202009%20-%20The%20Evolution%20of%20Modularity%20in%20the%20Mammalian%20Skull%20I%20-%20Morphological%20Integration%20Patterns%20and%20Magnitudes.pdf))

    __Abstract:__
    Morphological integration refers to the modular structuring of inter-trait relationships in an organism, which could bias the direction and rate of morphological change, either constraining or facilitating evolution along certain dimensions of the morphospace. Therefore, the description of patterns and magnitudes of morphological integration and the analysis of their evolutionary consequences are central to understand the evolution of complex traits. Here we analyze morphological integration in the skull of several mammalian orders, addressing the following questions: are there common patterns of inter-trait relationships? Are these patterns compatible with hypotheses based on shared development and function? Do morphological integration patterns and magnitudes vary in the same way across groups? We digitized more than 3,500 specimens spanning 15 mammalian orders, estimated the correspondent pooled within-group correlation and variance/covariance matrices for 35 skull traits and compared those matrices among the orders. We also compared observed patterns of integration to theoretical expectations based on common development and function. Our results point to a largely shared pattern of inter-trait correlations, implying that mammalian skull diversity has been produced upon a common covariance structure that remained similar for at least 65 million years. Comparisons with a rodent genetic variance/covariance matrix suggest that this broad similarity extends also to the genetic factors underlying phenotypic variation. In contrast to the relative constancy of inter-trait correlation/covariance patterns, magnitudes varied markedly across groups. Several morphological modules hypothesized from shared development and function were detected in the mammalian taxa studied. Our data provide evidence that mammalian skull evolution can be viewed as a history of inter-module parcellation, with the modules themselves being more clearly marked in those lineages with lower overall magnitude of integration. The implication of these findings is that the main evolutionary trend in the mammalian skull was one of decreasing the constraints to evolution by promoting a more modular architecture."

# Objetivos da Aula 3

- Calcular os componentes principais de cada espécie

## Componentes principais

A tecnica de componentes princiais (também conhecida como principal component analysis ou PCA) consiste em encontrar eixos ortogonais (com angulo de 90 graus entre eles) nos quais as variáveis medidas são não correlacionadas. Em outras palavras, nós descrevemos os individuos das nossas populações usando eixos relacionados às medidas tomadas em cada individuo, então um eixo corresponde ao comprimento do humero, outro eixo ao comprimento da ulna e assim por diante. Mas nesses eixos, que tem uma interpretação biológica clara, as medidas dos individuos em cada eixo são correlacionadas.

### Mudando os eixos

A analise de componentes principais consiste em encontrar eixos, criados a partir dos eixos originais, nos quais os individuos não são correlacionados. Antes de chegar nos componentes principais, vamos entender o que significa mudar os dados de eixos. Podemos ter, por exemplo, um eixo definido como uma combinação entre humero e ulna, e outro eixo correspondente à diferença entre humero e ulna. Vamos visualizar isso graficamente em duas dimensões, primeiro representando nos eixos originais as medidas de humero e ulna da espécie A. Vamos centralizar as medidas no zero para facilitar o gráfico, de modo que os valores nos eixos x e y vão ser diferenças das médias:

```{r, warning=FALSE, message=FALSE }
if(!require(evolqg)){install.packages("evolqg"); library(evolqg)}
data(dentus)

library(ggplot2)
# Separando e centralizando os dados da espécie A
dentus_A = as.data.frame(scale(dentus[dentus$species == "A",1:4], scale = FALSE))

# Plot de humero por ulna. Note que as duas medidas são correlacionadas
cor(dentus$humerus, dentus$ulna)
ggplot(dentus_A, aes(humerus, ulna)) + geom_point() + coord_fixed() + theme_bw()
```

Vamos agora incluir esses dois novos eixos hipotéticos, um na direção de aumento de humero e ulna (em azul), e um na direção de aumento de humero e diminuição de ulna (em vermelho).

```{r, warning=FALSE, message=FALSE }
ggplot(dentus_A, aes(humerus, ulna)) + geom_point() + coord_fixed() + geom_abline(intercept = 0, slope = 1, color = "blue", linetype = "dashed") + geom_abline(intercept = 0, slope = -1, color = "red", linetype = "dashed") + geom_segment(x = 0, y = 0, xend = 1, yend = 1, arrow = arrow(length = unit(0.03, "npc")), color = "blue") + geom_segment(x = 0, y = 0, xend = 1, yend = -1, arrow = arrow(length = unit(0.03, "npc")), color = "red") + theme_bw()
```

Podemos calcular as medidas de cada inviduo (scores) nesses novos eixos projetando os pontos. Para isso, temos que achar o ponto nas retas coloridas que seja o mais próximo do ponto a ser projetado. Isso envolve um pouco de trigonometria, mas vamos usar essa função que encontra o ponto numa reta mais próximo de um ponto qualquer. Eu mantive o código aqui a titulo de curiosidade, não precisam se preocupar com ele:

```{r}
# A reta é definida pelos pontos p_0 e p_1, e o ponto fora da reta é o q
pontoMaisProximo <- function(q, p_0, p_1){
  A = matrix(c(p_1[1] - p_0[1], p_1[2] - p_0[2],
               p_0[2] - p_1[2], p_1[1] - p_0[1]), byrow = TRUE, ncol = 2)
  b = -1*c(-1*  q[1]*(p_1[1] - p_0[1]) -   q[2]*(p_1[2] - p_0[2]),
           -1*p_0[2]*(p_1[1] - p_0[1]) + p_0[1]*(p_1[2] - p_0[2]))
  return(c(q, solve(A, b)))
}
projecoes_blue = data.frame(t(apply(dentus_A[,1:2], 1, pontoMaisProximo, c(0, 0), c(1, 1))))
names(projecoes_blue) = c("x1", "y1", "x2", "y2")
projecoes_red = data.frame(t(apply(dentus_A[,1:2], 1, pontoMaisProximo, c(0, 0), c(1, -1))))
names(projecoes_red) = c("x1", "y1", "x2", "y2")
ggplot(dentus_A, aes(humerus, ulna)) + geom_point() + coord_fixed() +
  geom_abline(intercept = 0, slope = 1, color = "blue", linetype = "dashed") +
  geom_abline(intercept = 0, slope = -1, color = "red", linetype = "dashed") +
  geom_segment(x = 0, y = 0, xend = 1, yend = 1, arrow = arrow(length = unit(0.03, "npc")), color = "blue") +
  geom_segment(x = 0, y = 0, xend = 1, yend = -1, arrow = arrow(length = unit(0.03, "npc")), color = "red") +
  geom_segment(data = projecoes_blue, aes(x = x1, xend = x2, y = y1, yend = y2), linetype = "dotted", color = "blue") +
  geom_segment(data = projecoes_red, aes(x = x1, xend = x2, y = y1, yend = y2), linetype = "dotted", color = "red") + theme_bw()
```

Nós podemos também rotacionar o dados, e plotar cada individuo como se os novos eixos "compostos", o azul e o vermelho, fossem os eixos x e y:

```{r}
# Rotacionando os dados usando uma matriz de rotação
dentus_A_rot = data.frame(as.matrix(dentus_A[,1:2]) %*% matrix(c(1/sqrt(2), 1/sqrt(2),
                                                                 1/sqrt(2), -1/sqrt(2)), 2, 2))
names(dentus_A_rot) = c("x", "y")
ggplot(dentus_A_rot, aes(x, y)) + geom_point() + coord_fixed() +
  geom_vline(xintercept = 0, color = "red", linetype = "dashed") +
  geom_hline(yintercept = 0, color = "blue", linetype = "dashed") +
  geom_segment(x = 0, y = 0, xend = 0, yend = 1, arrow = arrow(length = unit(0.03, "npc")), color = "red") +
  geom_segment(x = 0, y = 0, xend = 1, yend = 0, arrow = arrow(length = unit(0.03, "npc")), color = "blue") +theme_bw()
```

Qual será a correlação dos dados nesses novos eixos?

```{r}
cor(dentus_A_rot$x, dentus_A_rot$y)
```

Ou seja, eles ainda são correlacionados. Qual seriam os eixos que deixam nossos dados não correlacionados?

### Meu primeiro PCA

A analise de componentes principais encontra esses eixos não correlacionados usando a matriz de covariância. Por enquanto, vamos continuar com apenas duas medidas (humero e ulna da especie A) e tentar encontrar os eixos onde essas duas medidas não são correlacionadas. Para isso, vamos encontrar a matriz de covariância entre essas duas medidas:

```{r}
# matriz de covariância entre humero e ulna
cov_hu = cov(dentus_A[,1:2])
cov_hu
```

Para encontrar os componentes principais, vamos usar a função eigen:

```{r}
# Vamos usar a função eigen na matriz de covariância cov_hu
PC_hu = eigen(cov_hu)
PC_hu
```

O objeto de saida da eigen, que eu chamei de PC_hu, tem duas partes: values e vectors. O vectors é uma matriz $2\times2$, e cada coluna corresponde a um PC. O número de PCs é sempre o mesmo que o numero de eixos originais, afinal, eu precisava de 2 eixos para descrever os dados e uma rotação não vai alterar isso. Então, o primeiro componente principal da matriz de covariância entre humero e ulna é:

```{r}
# Primeiro usamos o operador $ para pegar a matriz de PCs (vectors),
# depois o operador [,1] para pegar a primeira coluna da matriz de PCs
PC_hu$vectors[,1]
```

Vamos colocar esses eixos no gráfico, como fizemos antes com os eixos azul e vermelho (vou manter o azul e o vermelho a titulo de comparação, até que nosso chute tinha sido bom!):

```{r, warning=FALSE, message=FALSE }
PC1 = PC_hu$vectors[,1]
PC2 = PC_hu$vectors[,2]

ggplot(dentus_A, aes(humerus, ulna)) + geom_point() + coord_fixed() +
  geom_abline(intercept = 0, slope = 1, color = "blue", linetype = "dashed") +
  geom_abline(intercept = 0, slope = -1, color = "red", linetype = "dashed") +
  geom_segment(x = 0, y = 0, xend = PC1[1], yend = PC1[2], arrow = arrow(length = unit(0.03, "npc")), color = "green") +
  geom_segment(x = 0, y = 0, xend = PC2[1], yend = PC2[2], arrow = arrow(length = unit(0.03, "npc")), color = "purple") + theme_bw()
```

Agora vamos rotacionar os dados para os eixos dados pelos PCs

```{r}
# Rotacionando os dados usando os PCs
dentus_A_rot_PCs = data.frame(as.matrix(dentus_A[,1:2]) %*% PC_hu$vectors)
names(dentus_A_rot_PCs) = c("x", "y")
ggplot(dentus_A_rot_PCs, aes(x, y)) + geom_point() + coord_fixed() +
  geom_vline(xintercept = 0, color = "purple", linetype = "dashed") +
  geom_hline(yintercept = 0, color = "green", linetype = "dashed") +
  geom_segment(x = 0, y = 0, xend = 0, yend = 1, arrow = arrow(length = unit(0.03, "npc")), color = "purple") +
  geom_segment(x = 0, y = 0, xend = 1, yend = 0, arrow = arrow(length = unit(0.03, "npc")), color = "green") +theme_bw()
```

E a correlação?

```{r}
round(cor(dentus_A_rot_PCs$x, dentus_A_rot_PCs$y), 8)
```


## PCA em todas as espécies

Agora vamos partir pra um exemplo de verdade e calcular os PCs dos nossos quatro caracteres para todas as espécies. Para isso, vamos calcular novamente nossas matrizes de covariância:

```{r}
# Vamos criar uma lista com todas as nossas matrizes de uma vez só:
cov_matrices = dlply(dentus, .(species), function(x) cov(x[,1:4]))

# Agora podemos acessar cada matriz individualmente colocando no final do nome da lista
# o operador $ seguido do nome da especie
# Por exemplo, essa é a matriz de covariância da espécie A:
cov_matrices$A
```

Para encontrar os componentes principais, vamos usar a função eigen:

```{r}
PCs_A = eigen(cov_matrices$A)
PCs_A
```

Agora o vectors é uma matriz $4\times4$ (começamos com 4 eixos), e cada coluna corresponde a um PC. Então, o primeiro componente principal de A é:

```{r}
# Primeiro usamos o operador $ para pegar a matriz de PCs (vectors),
# depois o operador [,1] para pegar a primeira coluna da matriz de PCs
PCs_A$vectors[,1]
```

Note como todos os elementos desse componente tem o mesmo sinal e magnitude parecida. Isso significa que ao longo da direção definida por esse eixo todas as medidas aumentam ou diminuem juntas. Componentes desse tipo são chamados de componentes de tamanho (size).

Podemos olhar pra o segundo componente, que tem valores positivos para humero e ulna, e negativos para femur e tibia. Ou seja, é uma direção ao longo da qual humero e ulna aumentam enquanto femur e tibia diminuem. Esse tipo de componente é um contraste entre os dois grupos de caracteres.

## Values?

Para entender o que são os values no objeto de saida da eigen(), vamos projetar nossos dados nos PCs:

```{r}
# Rotacionando os dados usando os PCs
dentus_A_rot_PCs = as.matrix(dentus_A[,1:4]) %*% PCs_A$vectors

# Primeiras linhas dos dados rotacionados
head(dentus_A_rot_PCs)
```

Agora vamos calcular a matriz de covariância desses dados rotacionados:

```{r}
round(cov(dentus_A_rot_PCs), 10)
```
 Primeiro, note que todos os valores fora da diagonal são zero. Isso é esperado, afinal é isso que a analise de componentes principais faz: encontra eixos onde nossos dados não são correlacionados. Agora, vamos olhar para a diagonal, as variâncias dos dados rotacionados. Compare essas variâncias com os valores na parte "values" da saida da função eigen().

Comparou?

São os mesmos valores. Os values são as variâncias nas direções dos componentes principais.

## O primeiro componente principal

Vocês leram sobre linhas de menor resistencia evolutiva no artigo do Schluter, e agora podemos entender porque essa linha corresponde ao primeiro componente principal. A quantidade de variação total na população é sempre preservada em todas essas analises que fizemos, afinal são só rotações. Para conferir isso, vamos somar as variâncias originais e somar as variâncias saindo da eigen():

```{r}
var(dentus_A$humerus) + var(dentus_A$ulna) + var(dentus_A$femur) + var(dentus_A$tibia)
sum(PCs_A$values)
```

A diferença é que usando os PCs como eixos para representar nossas variáveis, a variação é independente em cada eixo. Com isso, podemos simplesmente comparar as variâncias para saber em qual eixo está a maior parte da variação. Logo, o PC com maior variância corresponde ao eixo com maior variação fenotípica nos dados. Como evolução depende da variação disponível, a direção do primeiro componente principal é a direção que responde mais facilmente à seleção, ou seja, evolução é mais fácil ao longo do primeiro componente principal.

## PCA como analise exploratória

O objetivo dessa aula é só encontrar os PCs para todas as espécies, e vocês já sabem como faz isso nessa altura. Fora de biologia evolutiva, é comum PCA ser utilizado como uma analise exploratória e de redução dimensional. A ideia geral é sempre a mesma (encontrar eixos com variação independente), e eventualmente descrever os dados utilizando menos variáveis. É comum, por exemplo, utilizar apenas os scores nos primeiros componentes principais por eles responderem por grande parte da variação total.

Um uso possivel para PCA é encontrar grupos. Suponha que não soubessemos que nossos dados vem de cinco espécies distintas. Será que um PCA poderia ajudar? Vamos calcular os componentes principais da matriz de covariância total e fazer um gráfico dos scores (dados rotacionados) nos dois primeiros componentes principais:

```{r}
mat_total = cov(dentus[,1:4])
eigT = eigen(mat_total)
dentus_rot = data.frame(as.matrix(dentus[,1:4]) %*% eigT$vectors, species = dentus$species)
names(dentus_rot) = c("PC1", "PC2", "PC3", "PC4", "species")
ggplot(dentus_rot, aes(PC1, PC2)) + geom_point() + theme_bw()
```

Claramente existem grupos distintos nesses dados. Nós sabemos que eles correspondem a espécies diferentes, então vamos incluir essa informação como cores:

```{r}
ggplot(dentus_rot, aes(PC1, PC2, color = species)) + geom_point() + theme_bw()
```

Isso é reconfortante, mesmo sem saber as espécies de antemão conseguiriamos chegar em grupos de forma bastante satisfatória.

Além disso, podemos ver que boa parte da diferenciação entre espécies se dá ao longo do PC1 da matriz total. Como você interpreta esse fato? __Dica__: interprete o primeiro componente da matriz de covariância total.

# Leitura da Aula 4

- [Population divergence and morphometric integration in the greenfinch (Carduelis chloris) – evolution against the trajectory of least resistance?](http://onlinelibrary.wiley.com/doi/10.1046/j.1420-9101.1999.00013.x/abstract) ([pdf](https://github.com/lem-usp/site-bio208/raw/master/static/pdfs/artigos/Merila-Bjorklund-1999.pdf))

    __Abstract:__
    Theory predicts that genetic and phenotypic correlations among traits may direct the process of short-term evolution by limiting the directions of variation available to natural selection to act on. We studied correlations between 14 skeletal traits in 10 geographically distinct and relatively young greenfinch (Carduelis chloris) populations to unravel whether the divergence among populations has occurred into directions predicted by the within-population correlations (cf. drift/correlated responses models), or whether it is better explained by ‘adaptive’ models, which predict no necessary association between within- and among-population correlations (allometries). We found that the within-population character correlations (or covariances) did not predict character divergence between populations. This was because the first eigenvector of the among-population correlation/covariance matrix, summarizing the major dimension of divergence, was a bipolar body:beak dimension, and distinct from the (≈ isometric) first eigenvector of within-population matrix. Hence, as the divergence among greenfinch populations cannot be satisfactorily accommodated by drift/correlated response models, an adaptive basis for divergence is suggested. The second major axis of within-population variation was a classical ‘group size’ factor revealing that beak size was more or less free to vary independently of body size. Consequently, even if the divergence among populations cannot be simply accommodated to expectations of drift and correlated response models, it is striking that the most pronounced size-independent (nonallometric) changes had occurred along the second largest dimension of variance. This could mean that selection pressures which shape integration within populations are the same as those that cause divergence among populations. A relaxed beak:body integration could also occur as a result of species level selection favouring taxa in which independent evolution of beak and body is made possible.

# Objetivos da Aula 4

- Estimar os estados ancestrais para os 4 caracteres em todos os nós da filogenia;
- Estimar a diferença nas médias entre ancestrais e descendentes ao longo da filogenia ($\Delta z$).

__Objetivo Bonus!__

- Estimar a correlação entre os $\Delta z$  que levaram às espécies atuais e seus primeiros componentes principais.

## Estados ancestrais

Essa aula se baseia na ideia de usar medidas em espécies ou populações atuais e as relações filogenéticas entre elas para estimar estados de caracteres ancestrais. (Note que a ideia é muito diferente de uma análise filogenética, nós não queremos usar os estados atuais para encontrar a filogenia). Para caracteres continuos, imagine que as elipses na figura a seguir sejam um caráter a ser reconstruido ao longo da filogenia:

![](./ancestral_ilustration.png)

Existem dois métodos populares e fáceis de usar no R para reconstrução de caracteres ancestrais: a parcimônia quadrada e a máxima verossimilhança. Ambos dão o mesmo resultado quando a filogenia usada não inclui os tamanhos de ramo. Cada método tem sua lógica e suas vantágens e desvantagens:

- Parcimônia quadrada:

    - Minimiza a mudança evolutiva quadrada ao longo da filogenia;

    - Ignora os tamanhos de ramo.

- Máxima verossimilhança:

    - Encontra os estados ancestrais mais plausíveis, assumindo que a distribuição das médias das espécies é multivariada normal;

    - Incorpora tamanho de ramo;

    - Pode ser usado para estimar taxas evolutivas usando um modelo de evolução por movimento Browniano.

Outra opção é a parcimônia linear, que não está disponível no R, mas pode ser feita usando o programa [mesquite](http://mesquiteproject.wikispaces.com/)

Aqui vamos usar o método de máxima verossimilhança. Primeiro, como sempre, vamos carregar os dados e carregar alguns pacotes:

```{r, warning=FALSE, message=FALSE }
if(!require(evolqg)){install.packages("evolqg"); library(evolqg)}
if(!require(ape)){install.packages("ape"); library(ape)}
data(dentus)
```

Agora vamos colocar nossa filogenia num objeto do R, usand uma notação parentética:

```{r, warning=FALSE, message=FALSE}
TREE <- "(A:4,(B:3,(C:2,(D:1, E:1):1):1):1);"
tree <- read.tree(text = TREE)
tree$tip.label = c("A", "B", "C", "D", "E")
tree$node.label = c("root", "BCDE", "CDE", "DE")
plot(tree, show.node.label=TRUE)
nodelabels()
```

Para fazer as estimativas ancestrais, precisamos calcular as médias atuais. Podemos fazer isso rapidamente usando a função ddply do pacote [plyr](http://had.co.nz/plyr/).

```{r}
dentus_means = ddply(dentus, "species", numcolwise(mean))
dentus_means
```

Cada coluna do objeto dentus_means contém as médias de um caráter para cada espécie. A função de reconstrução de caracteres ancestrais do pacote ape usa esses valores e a arvore filogenética para fazer a reconstrução:

```{r}
humerus_ancestral = ace(dentus_means$humerus, tree)
humerus_ancestral
```

Novamente o objeto de saida tem várias partes, chamadas ace, sigma2 e CI95. ace são as estimativas propriamente ditas; sigma2 é um parâmetro ligado à taxa de evolução sobre um modelo de movimento browniano; e CI95 são os intervalos de confiânça para as estimativas em cada nó. Nesse curso vamos nos preocupar apenas com as estimativas, e podemos acessá-las usando o operador $:

```{r}
humerus_ancestral$ace
```

Isso é um vetor com um valor para cada nó, que estão numerados. Podemos ver na filogenia a quais nós correspondem esses números.
__Pergunta:__ De acordo com essa reconstrução, o humero está aumentando ou diminuindo a medida de subimos nos nós da filogenia?

Vamos agora calcular os estados ancestrais para os outros caracteres:

```{r, warning=FALSE, message=FALSE}
dentus_ancestral = sapply(dentus_means[2:5], function(x) ace(x, tree)$ace)
dentus_ancestral
```

Vamos incluir uma coluna de "especie" nessa tabela de estados ancestrais:

```{r}
dentus_ancestral = data.frame(species = c("root", "BCDE", "CDE", "DE"), dentus_ancestral)
```

Agora podemos juntar ela com nossa tabela de médias antiga, e ficar com tudo no mesmo objeto:

```{r}
dentus_means_ace = rbind(dentus_means, dentus_ancestral)
dentus_means_ace
```

Essa é uma ótima tabela, e vc pode salvar ela pra um arquivo usando o comando:

```{r, eval=FALSE}
write.csv(dentus_means_ace, "meu_arquivo_de_medias.csv")
```

Essa tabela é ótima para o excel (guarde ela! vamos usar na próxima aula (acho)), mas seria melhor ter um objeto que facilitasse as contas. Para isso, vamos transformar essa tabela em uma lista:

```{r}
l_dentus = dlply(dentus_means_ace, .(species), numcolwise(identity))
```

Esse objeto l_dentus é muito conveniente, por que com ele podemos acessar as médias de qualquer ponto da filogenia usando o operador $. Por exemplo, para obter a média da raiz da filogenia:

```{r}
l_dentus$root
```

Agora podemos usar esse vetores de caracteres para calcular nossos vetores de mudança fenotípica ao longo da filogenia, os famigerados $\Delta z$. Para isso, é só subtrair o descendente do ancestral. Por exemplo, para o $\Delta z$ associado ao ramo que vai do nó DE para o terminal D, fazemos:

```{r}
deltaZ_DE_D = l_dentus$D - l_dentus$DE
deltaZ_DE_D
```

Isso é o vetor de mudança evolutiva entre a espécie D e seu ancestral mais próximo.

## Correlação de vetores

Para entender o conceito de correlação de vetores vamos precisar de alguns elementos. Primeiro, vamos definir o produto interno entre dois vetores. Um produto interno é uma operação que leva de um par de vetores para um número e respeita algumas propriedades. Para as nossas aplicações, o produto interno entre os vetores $\mathbf a$ e $\mathbf b$ é definido como a __soma dos produtos cruzados entre os elementos dos dois vetores__:

$$
\mathbf a \cdot \mathbf b = \sum_{i=1}^n a_i\times b_i
$$

Então, se $\mathbf a = \{1, 2, 3\}$ e $\mathbf b = \{4, 5, 6\}$, o produto interno fica:

$$
\mathbf a \cdot \mathbf b = a_1 \times b_1 + a_2 \times b_2 + a_3 \times b_3 = 1 \times 4 + 2 \times 5 + 3 \times 6 = 32
$$

Podemos usar o produto interno para definir a norma, ou comprimento, de um vetor. A norma é a __raiz quadrada do produto interno do vetor por ele mesmo__:

$$
\| \mathbf a \| = \sqrt{a \cdot a}
$$

Em duas dimensões isso é o Teorema de Pitágoras! (faça um desenho de um vetor em duas dimensões e tente ver isso (se você não lembra o Teorema de Pitágoras é meio que problema seu cara, olha na wikipedia, sei lá (e você achou que nunca mais fosse precisar do Teorema de Pitágoras ein!))).


Agora vamos pensar na norma ao quadrado da diferença de dois vetores:

$$
\|(a-b)\|^2 = (a - b) \cdot (a-b) = a \cdot a + b \cdot b - 2(a \cdot b) = \|a\|^2 + \|b\|^2 - 2(a \cdot b)
$$

Guarde esse resultado e vamos lembrar da lei dos cossenos, que, usando a notação dessa figura:

![](cos_rule.png)

Pode ser escrita como:

$$
c^2 = \|a-b\|^2 = \|a\|^2 + \|b\|^2 - 2\|a\|\|b\|cos\theta
$$

Juntando a equação para $\|a-b\|^2$ com a lei dos cossenos:

$$
\|a\|^2 + \|b\|^2 - 2\|a\|\|b\|cos\theta = \|a\|^2 + \|b\|^2 - 2(a \cdot b)
$$

$$
a \cdot b = \|a\|\|b\|cos\theta
$$

Ou:

$$
cos\theta = \frac{a \cdot b}{\|a\|\|b\|}
$$

Ou seja, o cosseno do angulo entre dois vetores pode ser escrito como o __produto interno entre eles dividido pelo produto das suas normas__. Esse valor de cosseno pode ser utilizado como uma medida de similaridade de vetores no que se refere à sua direção. Se dois vetores apontam no mesmo sentido, o angulo entre eles é zero e o cosseno é 1; se eles apontam em direções ortogonoais, o angulo entre eles é de noventa graus e o cosseno é zero.

Para entender por que nós costumamos chamar essa medida de correlação de vetores, pense na equaçao da correlação entre $x$ e $y$:

$$
Cor(x, y) = \frac{1}{N}  \frac{\sum_{i = 1}^{N} (x_i - \overline{x})(y_i - \overline y)}{\sigma_x \sigma_y}
$$

Abrindo os desvios padrão no denominador:

$$
Cor(x, y) = \frac{1}{N} \frac{\sum_{i = 1}^{N}  (x_i - \overline{x})(y_i - \overline y)}{\sqrt{\frac{1}{N} \sum_{i = 1}^{N} (x_i - \overline{x})^2 \frac{1}{N} \sum_{i = 1}^{N} (y_i - \overline{y})^2}}
$$

Os $1/N$ cancelam, e ficamos com:

$$
Cor(x, y) =  \frac{\sum_{i = 1}^{N} (x_i - \overline{x})(y_i - \overline y)}{\sqrt{ \sum_{i = 1}^{N} (x_i - \overline{x})^2 } \sqrt{ \sum_{i = 1}^{N} (y_i - \overline{y})^2}}
$$

Agora imagine que os valores estão centrados na média, então $\overline x$ e $\overline y$ são zero:

$$
Cor(x, y) =  \frac{\sum_{i = 1}^{N} x_iy_i}{\sqrt{ \sum_{i = 1}^{N} x_i^2 } \sqrt{ \sum_{i = 1}^{N} y_i^2}}
$$

Isso é exatamente a mesma coisa que:

$$
Cor(x, y) =  \frac{x \cdot y}{\|x\|\|y\|}
$$

Que é a formula para o cosseno do angulo entre $x$ e $y$! Então, o cosseno do angulo entre dois vetores e a correlação entre eles são a mesma coisa se a média deles for zero. Dai o nome correlação de vetores para o cosseno do angulo entre eles.

### Calculando correlações no R

Para calcular correlações de vetor no R, vamos escrever algumas funções que façam tudo que a gente precisa.

Primeiro uma para o produto interno:
```{r}
prod_interno = function(x, y) sum(x * y)
```

Depois uma para a norma:

```{r}
norma = function(x) sqrt(prod_interno(x, x))
```

E finalmente uma para a correlação:

```{r}
corVector = function(x, y) prod_interno(x, y)/(norma(x)*norma(y))
```

Agora podemos usar essa função para calcular correlações entre todos os nossos vetores e responder perguntas evolutivas! Por exemplo, será que a diferenciação da população D se deu ao longo da sua linha de menor resistencia evolutiva?

```{r}
cov_matrices = dlply(dentus, .(species), function(x) cov(x[,1:4]))
PC1_D = eigen(cov_matrices$D)$vectors[,1]
abs(corVector(PC1_D, deltaZ_DE_D))
```

Parce que sim!!


Agora divirta-se, calcule os $\Delta z$ ao longo da filogenia e use a correlação de vetores para investigar seus dados. Os $\Delta z$ são todos na mesma direção? Como os $\Delta z$ nos teminais se alinham com as respectivas linhas de menor resistência? Pense em quais perguntas você é capaz de responder com esses dados agora.

# Leitura da Aula 5

- [Did Natural Selection or Genetic Drift Produce the Cranial Diversification of Neotropical Monkeys?](http://www.journals.uchicago.edu/doi/10.1086/381693) ([pdf](https://github.com/lem-usp/site-bio208/raw/master/static/pdfs/artigos/Marroig%2C%20Cheverud%20-%202004%20-%20Did%20natural%20selection%20or%20genetic%20drift%20produce%20the%20cranial%20diversification%20of%20neotropical%20monkeys.pdf))

    __Abstract:__
    A central controversy among biologists is the relative importance of natural selection and genetic drift as creative forces shaping biological diversification (Fisher 1930; Wright 1931). Historically, this controversy has been an effective engine powering several evolutionary research programs during the last century (Provine 1989). While all biologists agree that both processes operate in nature to produce evolutionary change, there is a diversity of opinion about which process dominates at any particular organizational level (from DNA and proteins to complex morphologies). To address this last level, we did a broadscale analysis of cranial diversification among all living New World monkeys. Quantitative genetic models yield specific predictions about the relationship between variation patterns within and between populations that may be used to test the hypothesis that genetic drift is a sufficient explanation for morphological diversification. Diversity at several levels in a hierarchy of taxonomic/phylogenetics relationship was examined from species within genera to families within superfamilies. The major conclusion is that genetic drift can be ruled out as the primary source of evolutionary diversification in cranial morphology among taxa at the level of the genus and above as well as for diversification of most genera. However, drift may account for diversification among species within some Neotropical primate genera, implying that morphological diversification associated with speciation need not be adaptive in some radiations.

# Objetivos da Aula 5

- Estimar as matrizes de covariância dos nós ancestrais
    - Estimar os PCs das matrizes ancestrais
- Comparar os componentes principais das matrizes dentro e entre grupos

## Matrizes ancestrais

O calculo das matrizes ancestrais é feito como uma média ponderada das matrizes ao longo da filogenia. Isso é equivalente a calcular uma matriz de covariância usando a formula usual da covariância, mas substituindo a média global pela média da espécie do indivíduo sendo considerado. Se $\overline{z}_{sp[k]}^i$ representa a média da espécie do indivíduo $k$ para o caráter $i$, a matriz de covariância para um nó ancestral é dada por:

$$
Cov(z^i, z^j) = \frac{1}{N} \sum_{k = 1}^{N} (z_{k}^i - \overline{z}_{sp[k]}^i)(z_{k}^j - \overline{z}_{sp[k]}^j)
$$

Onde a soma é feita para todos os indivíduos para a espécies descendentes do nó em questão. Vamos testar essa história. Primeiro vamos carregar os dados e calcular as matrizes para todas as espécies atuais.

```{r}
if(!require(evolqg)){install.packages("evolqg"); library(evolqg)}
data(dentus)
cov_matrices = dlply(dentus, .(species), function(x) cov(x[,1:4]))
```

A matriz do ancestral comum entre as espécies D e E é dada pela ponderada entre as matrizes atuais:

```{r}
cov_matrix_ED = (60 * cov_matrices$E + 60 * cov_matrices$D)/120
cov_matrix_ED
```

A ideia é que essa matriz é a mesma coisa que fazer a covariância normalmente, mas usando a média das espécies separadamente. Vamos usar a formula de covariância diretamente, mas controlando para o número de graus de liberdade:

```{r}
means = daply(dentus, .(species), function(x) colMeans(x[,1:4]))
dentus_DE = dentus[dentus$species == "D" | dentus$species == "E",]
medias_DE = means[dentus[dentus$species == "D" | dentus$species == "E", 5],]

# Essa correção pelos graus de liberdade é meio confusa, mas pense que a var()
#vai tirar um grau de liberdade, mas a gente calculou duas médias,
# então precisamos tirar outro!
(119/(119-1)) * var(dentus_DE[,1:4] - medias_DE)
```

Bacana, deu a mesma coisa. Outra solução nesse caso é escrever o problema como uma regressão linear e extrair a covariância dos residuos:

```{r}
residuos_DE = residuals(lm(as.matrix(dentus_DE[,1:4])~dentus_DE[,5]))
(119/(119-1)) * cov(residuos_DE)
```

O resultado é o mesmo. Você pode ler o termo `as.matrix(dentus_DE[,1:4])~dentus_DE[,5]` como: _as colunas de 1 a 4 do objeto dentus_DE em função da quinta coluna do objeto dentus_DE_. Você pode pensar no operado `~` como um "_em função de_". Variáveis dependentes à esquerda e preditoras à direita.

Um jeito mais simples ainda é usar a função CalculateMatrix() do pacote evolqg, que calcula os graus de liberdade corretamente a partir do modelo linear:

```{r}
CalculateMatrix(lm(as.matrix(dentus_DE[,1:4])~dentus_DE[,5]))
```

Ótimo, temos vários jeitos de calcular as matrizes de covariancia usando as médias de cada espécie. Essa matriz ponderada de vários grupos ao mesmo tempo costuma ser chamada de $\mathbf{W}$, ou matriz ponderada dentro de grupos (within-groups, dai o $\mathbf{W}$).

Vamos calcular então a $\mathbf{W}$ de todos os grupos, que também é a nossa matriz ancestral da raiz da filogenia:

```{r}
W = CalculateMatrix(lm(as.matrix(dentus[,1:4])~dentus$species))
W
```

Note que usamos todos os caracteres, que estão no objeto dentus, como as variáveis dependentes; e usamos todas as espécies como variáveis preditoras. Isso garante que a função lm() irá calcular uma média por espécie.

Tudo isso é bom e poderiámos calcular as matrizes ancestrais assim para os nossos poucos nós (afinal são só 4). Mas estamos com pressa, todo mundo aqui tem filho pra criar, então vamos usar a filogenia e as matrizes atuais para calcular as matrizes ancestrais todas de uma vez só.

Primeiro a filogenia:
```{r}
if(!require(ape)){install.packages("ape"); library(ape)}
TREE <- "(A:4,(B:3,(C:2,(D:1, E:1):1):1):1);"
tree <- read.tree(text = TREE)
tree$tip.label = c("A", "B", "C", "D", "E")
tree$node.label = c("root", "BCDE", "CDE", "DE")
```

E agora usamos a filogenia e a lista de matrizes atuais na funçao PhyloW para calcular uma matriz ancestral (ou dentro de grupos) para cada nó:
```{r}
all_cov_matrices = PhyloW(tree, cov_matrices)
attributes(all_cov_matrices)$split_labels = attributes(all_cov_matrices)$names
```

Agora podemos usar o operador $ para acessar qualquer matriz:

```{r}
all_cov_matrices$root
```

Bateu com a W?

### PCs das matrizes ancestrais

Agora temos os ingredientes para explorar se as mudanças evolutivas ao longo da filogenia ($\Delta z$) são alinhados com a as linhas de menor resistencia evolutiva ancestrais (PCs das matrizes ancestrais).

Vamos calcular o primeiro e segundo PCs das matrizes ancestrais:
```{r}
all_pc1 = llply(all_cov_matrices, function(x) eigen(x)$vectors[,1])
all_pc2 = llply(all_cov_matrices, function(x) eigen(x)$vectors[,2])

#mesmo esquema:
all_pc1$root
```

Agora que você tem os PCs e os $\Delta z$, sabe fazer uma correlação de vetor e sabe como interpretar as correlações, podemos juntar tudo isso! Calcule e interprete as correlações entre $\Delta z$ e PC1 e PC2 ao longo da filogenia.

## Matrizes dentro e entre grupos

Vamos usar nosso recém adquirido conhecimento do que é uma matriz dentro de grupos para reproduzir a análise do artigo da semana passada. Os autores usaram o seguinte argumento: se a diversificação de um grupo de espécies se deu por deriva ou seleção correlacionada, esperamos que as médias das espécies estejam distribuidas de acordo com a matriz de covariância ancestral. Graficamente em duas dimensões seria algo como:

```{r, out.width = "400px", echo = FALSE}
knitr::include_graphics("drift.png")
```

Cada elipse cinza representa uma população atual. A elipse amarela representa a matriz de covariância ancestral (dentro de grupos), e a elipse grande _salmon_ é a matriz de covariância entre as populações atuais. Sobre deriva, esperamos que a matriz amarela e a salmão estejam alinhadas.

A matriz amarela é a nossa $\mathbf{W}$, que já calculamos. Agora, vamos calcular a matriz de covariância entre grupos (between-groups), a matriz $\mathbf{B}$.

A matrix $\mathbf{B}$, oficialmente, é a matriz residual quando a variação dentro de grupos é excluída da variação total. Para fazer essa conta, podemos usar novamente a função lm() e obter a soma dos residuos ao quadrado (uma espécie de medida da variação total de todos os individuos em relação à média). Fazemos isso tanto para a variação entre grupos quanto dentro de grupos:

```{r}
# Modelo sem preditores (só com um intercepto) me da os residuos em relação à media total
residuos_T = residuals(lm(as.matrix(dentus[,1:4]) ~ 1))

# Modelo com espécie como preditor me dá os residuos dentro de grupos
residuos_W = residuals(lm(as.matrix(dentus[,1:4]) ~ dentus$species))

# Agora calculamos a soma dos residuos ao quadrado
sq_res_T = t(residuos_T) %*% residuos_T
sq_res_W = t(residuos_W) %*% residuos_W

# A diferença entre esses dois é a soma dos residuos ao quadrado entre grupos
sq_res_B = sq_res_T - sq_res_W

# A média (ajustada pelos graus de liberdade) disso na população é a
# matriz de covariância entre grupos
N_ind = 300
B = sq_res_B/(N_ind-1)
B
```

Outra opção, mais simples, é a aproximar a $\mathbf{B}$ como a matriz de covariância entre as médias das espécies:

```{r}
means = daply(dentus, .(species), function(x) colMeans(x[,1:4]))
cov(means)
```

Não é idêntico, mas tá quase lá. Com mais espécies essas duas estimativas ficariam cada vez mais similares.

Agora podemos comparar os componentes principais entre essas duas matrizes ($\mathbf{B}$ e $\mathbf{W}$)

```{r}
PC1_B = eigen(B)$vectors[,1]
PC1_W = eigen(W)$vectors[,1]

# Use a função de correlação entre vetores que a gente viu na aula passada
corVector(PC1_B, PC1_W)
```

O que essa correlação te diz sobre a variação entre e dentro de grupos? Quais processos evolutivos poderiam ter levado a isso?

# Leitura da Aula 6

- [SIZE AS A LINE OF LEAST EVOLUTIONARY RESISTANCE: DIET AND ADAPTIVE MORPHOLOGICAL RADIATION IN NEW WORLD MONKEYS](http://onlinelibrary.wiley.com/doi/10.1111/j.0014-3820.2005.tb01049.x/abstract) ([pdf](https://github.com/lem-usp/site-bio208/raw/master/static/pdfs/artigos/Marroig%2C%20Cheverud%20-%202005%20-%20Size%20as%20a%20line%20of%20least%20evolutionary%20resistance%20diet%20and%20adaptive%20morphological%20radiation%20in%20New%20World%20monkey.pdf))

    __Abstract:__
    New World monkeys (NWM) display substantial variation (two orders of magnitude) in body size. Despite this, variation in skull size and associated shape show a conserved allometric relationship, both within and between genera. Maximum likelihood estimates of quantitative ancestral states were used to compare the direction of morphological differentiation with the phenotypic (pmax) and genetic (gmax) lines of least evolutionary resistance (LLER). Diversification in NWM skulls occurred principally along the LLER defined by size variation. We also obtained measures of morphological amount and pace of change using our skull data together with published genetic distances to test whether the LLER influenced the amount and pace of diversification. Moreover, data on an ecological factor (diet) was obtained from the literature and used to test the association of this niche-related measure with the morphological diversification. Two strategies were used to test the association of LLER with the morphological and dietary amount and pace of change, one focusing on both contemporary genera and maximum likelihood reconstructed ancestors and the other using only the 16 contemporary genera in a phylogenetic comparative analysis. Our results suggest that the LLER influenced the path, amount, and pace of morphological change. Evolution also occurred away from the LLER in some taxa but this occurred at a slower pace and resulted in a relatively low amount of morphological change. We found that longer branch lengths (time) are associated with larger differences in pmax orientation. However, on a macroevolutionary scale there is no such trend. Diet is consistently associated with both absolute size differences and morphological integration patterns, and we suggest that this ecological factor might be driving adaptive radiation in NWM. Invasion of diet-based adaptive zones involves changes in absolute size, due to metabolic and foraging constraints, resulting in simple allometric skull diversification along the LLER. While it is clear that evolutionary change occurred along the LLER, it is not clear whether this macroevolutionary pattern results from a conservation of within-population genetic covariance patterns or long-term adaptation along a size dimension or whether both constraints and selection were inextricably involved.

## Leitura complementar para ter os $\beta$ corretos:

- [MODULARITY, NOISE, AND NATURAL SELECTION](http://onlinelibrary.wiley.com/doi/10.1111/j.1558-5646.2011.01555.x/full) ([pdf](https://github.com/lem-usp/site-bio208/raw/master/static/pdfs/artigos/Marroig%2C%20Melo%2C%20Garcia%20-%202012%20-%20Modularity%2C%20noise%2C%20and%20natural%20selection.pdf))

    __Abstract:__
    Most biological systems are formed by component parts that are to some degree interrelated. Groups of parts that are more associated among themselves and are relatively autonomous from others are called modules. One of the consequences of modularity is that biological systems usually present an unequal distribution of the genetic variation among traits. Estimating the covariance matrix that describes these systems is a difficult problem due to a number of factors such as poor sample sizes and measurement errors. We show that this problem will be exacerbated whenever matrix inversion is required, as in directional selection reconstruction analysis. We explore the consequences of varying degrees of modularity and signal-to-noise ratio on selection reconstruction. We then present and test the efficiency of available methods for controlling noise in matrix estimates. In our simulations, controlling matrices for noise vastly improves the reconstruction of selection gradients. We also perform an analysis of selection gradients reconstruction over a New World Monkeys skull database to illustrate the impact of noise on such analyses. Noise-controlled estimates render far more plausible interpretations that are in full agreement with previous results.

# Objetivos da aula 6

- Calcular os gradientes de seleção ($\beta$) ao longo da filogenia
- Calcular a correlação entre gradientes de seleção resposta à seleção ($\Delta z$)

## Equação do criador

Para entender a equação de resposta à seleção, vamos lembrar da herdabilidade (relacionada com a covariância entre pais e filhos). Pense que temos uma população expressando um caráter quantitativo qualquer com herdabilidade ($h^2$) de 0.6. Isso significa que nessa população, se fizermos uma gráfico com a média do valor do caráter nos pais no eixo $x$ e o valor do caráter dos filhos no eixo $y$, centralizando o grafico na média dos pais, teriamos alguma coisa assim:

```{r, echo = FALSE}
library(mvtnorm)
library(ggplot2)
set.seed(42)
x = rnorm(100, 0, 1)
y = 0.6 * x + rnorm(100, 0, 0.3)
data = as.data.frame(scale(data.frame(x, y), scale = FALSE))
model = lm(data$y ~ data$x)
c = coef(model)
ggplot(data, aes(x, y)) + geom_point() + theme_bw() + coord_fixed() + labs(x = "Fenótipo dos pais", y = "Fenótipo dos filhos") + geom_hline(yintercept = 0) + geom_vline(xintercept = 0)
```

Nesta população, vamos aplicar um regime de seleção direcional no fenótipo dos pais. Apenas pais com fenótipo uma unidade maior que á média irão deixar descendentes. Vamos usar o gráfico para descobrir a nova média dos filhos:

```{r, echo = FALSE}
x_mean = mean(data[data$x > 1, "x"])
y_mean = mean(data[data$x > 1, "y"])
shade <- data.frame(x = c(1, 1, 2.5, 2.5, 1), y = c(-2, 2, 2, -2, -2))
ggplot(data, aes(x, y)) + geom_polygon(data = shade, aes(x, y), fill = "lightblue", alpha = 0.5) + geom_point() + theme_bw() + coord_fixed() + labs(x = "Fenótipo dos pais", y = "Fenótipo dos filhos") + geom_hline(yintercept = 0) + geom_vline(xintercept = 0) + geom_smooth(method = "lm", color = "blue", se = FALSE) + geom_segment(x = x_mean, xend=x_mean, y = 0, yend = c[2] * x_mean, linetype = "dashed", size = 2)  + geom_segment(x = 0, xend=x_mean, y = c[2] * x_mean, yend = c[2] * x_mean, linetype = "dashed", size = 2)
```

A região em azul representa o limiar de seleção (apenas pais maiores que 1 deixam descententes). A média dos pais depois da seleção está marcada pela linha tracejada vertical. Usando uma regressão linear, podemos descobrir a média dos filhos dos pais que sobrevivem à seleção. A linha tracejada horizontal marca a média dos filhos após a seleção. O coeficiente de inclinação da regressão entre pais e filhos é a herdabilidade do caráter na população. Como nós centralizamos os pais e a reta de regressão passa pelo zero, sabemos que a média dos pais e filhos antes da seleção eram iguais.

A diferença entre a média dos pais antes e depois da seleção é chamada de diferencial de seleção ($S$), enquanto a diferença na média dos filhos é chamada de resposta à seleção ($R$). A razão entre ela, ou o coeficiente da inclinação da reta de regressão entre pais e filhos, ou a tangente do angulo da reta, é a herdabilidade ($h^2$). Graficamente:

```{r, echo = FALSE}
S = data.frame(x = c(0, 0, x_mean, x_mean),
               y = c(0, - 0.1, - 0.1, 0))

R = data.frame(x = c(-0.1, -0.1, 0),
               y = c(0, c[2] * x_mean, c[2] * x_mean))

ggplot(data, aes(x, y)) + geom_polygon(data = shade, aes(x, y), fill = "lightblue", alpha = 0.5) + geom_point(alpha = 0.3) + theme_bw() + coord_fixed() + labs(x = "Fenótipo dos pais", y = "Fenótipo dos filhos") + geom_hline(yintercept = 0) + geom_vline(xintercept = 0) + geom_smooth(method = "lm", color = "blue", se = FALSE) + geom_segment(x = x_mean, xend=x_mean, y = 0, yend = c[2] * x_mean, linetype = "dashed", size = 2)  + geom_segment(x = 0, xend=x_mean, y = c[2] * x_mean, yend = c[2] * x_mean, linetype = "dashed", size = 2) + geom_line(data = S, color = "red") + annotate("text", x = 0.7, y = -0.2, label = "S", size = 5) + geom_line(data = R, color = "red") + annotate("text", x = -0.2, y = 0.45, label = "R", size = 5) + geom_segment(x = -0.1, xend = 0, y = 0, yend = 0, color = "red")
```

Juntando tudo isso, podemos escrever a equação do criador:

$$
R = h^2S
$$

Ou seja, a resposta à seleção direcional é uma combinação entre a intensidade de seleção (quanto maior o $S$ maior a intensidade de seleção) e a variação disponível que é herdável (a herdabilidade, a regressão entre pais e filhos). Nesse caso, temos $S = 1.44$, $h^2 = 0.6$ e, portanto, $R = 0.87$.

Em condições razoáveis, o coeficiente da regressão entre pais e filhos vai ser igual à razão entre a variância nos valores de acasalamento dos pais (variancia aditiva, $V_a$) e a variância fenotípica total ($V_p$). Por isso, é comum encontrarmos a equação do criador escrita como $R = \frac{V_a}{V_p}S$ nos livros texto. A formulação como a regressão entre pais e filhos é mais geral, e a versão usando a partição de variâncias é mais fácil de ser mensurada.

## Equação de Lande

O que acontece quando temos mais de um caráter no sistema? Para entender o problema, pense que estamos olhando para dois caracteres nos pais, e aplicando seleção em apenas um deles. Imagine que esses dois caracteres tenham uma correlação fenotípica de 0.8 entre eles:

```{r, echo = FALSE}
set.seed(42)
xy = data.frame(rmvnorm(100, sigma = matrix(c(1, 0.8, 0.8, 1), 2, 2)))
names(xy) = c("x","y")
shade <- data.frame(x = c(1, 1, 2.5, 2.5, 1), y = c(-2, 2.8, 2.8, -2.5, -2.5))
ggplot(xy, aes(x, y)) + geom_polygon(data = shade, aes(x, y), fill = "lightblue", alpha = 0.5) + geom_point() + theme_bw() + coord_fixed() + labs(x = "Caráter x nos pais", y = "Caráter y nos pais") + geom_hline(yintercept = 0) + geom_vline(xintercept = 0)
```

Da mesma forma que a correlação entre pais e filhos impõem uma resposta, a correlação entre caracteres impõem um diferencial de seleção correlacionado. Então, se existe um $S_x$, a correlação entre $x$ e $y$ leva a um $S_y$:

```{r, echo = FALSE}
x_mean = mean(xy[xy$x > 1, "x"])
y_mean = mean(xy[xy$x > 1, "y"])
S_x = data.frame(x = c(0, 0, x_mean, x_mean),
               y = c(0, - 0.1, - 0.1, 0))

S_y = data.frame(x = c(-0.1, -0.1, 0),
               y = c(0, y_mean, y_mean))

ggplot(xy, aes(x, y)) + geom_polygon(data = shade, aes(x, y), fill = "lightblue", alpha = 0.5) +
  geom_point(alpha = 0.3) + theme_bw() + coord_fixed() +
  labs(x = "Caráter x nos pais", y = "Caráter y nos pais") +
  geom_hline(yintercept = 0) + geom_vline(xintercept = 0) +
  geom_line(data = S_x, color = "red") + annotate("text", x = x_mean/2, y = -0.3, label = "S[x]", size = 5, parse = TRUE) +
  geom_line(data = S_y, color = "red") + annotate("text", x = -0.3, y = y_mean/2, label = "S[y]", size = 5, parse = TRUE) +
  geom_segment(x = -0.1, xend = 0, y = 0, yend = 0, color = "red")
```

Esse fenômeno do diferencial de seleção correlacionado complica nossa vida, afinal, como saber qual caráter está sofrendo seleção? Nesse caso, $S = [S_x, S_y] = [1.43, 1.15]$, ambos os caracteres tem médias diferentes depois da seleção. A solução é transformar os dados, colocando eles na escala da matriz de covariação fenotípica. Fazemos isso multiplicando os dados pelo inverso da matriz fenotípica, e o resultado é o seguinte:

```{r, echo = FALSE}
P = cov(xy)
xy_p = data.frame(as.matrix(xy) %*% solve(P))
xy_p = data.frame(t(apply(as.matrix(xy), 1, function(x) solve(P, x))))
names(xy_p) = c("x", "y")
xy_p$Selection = ifelse(xy$x > 1, "Survives", "Dies")
shade <- data.frame(x = c(1, 1, 2.5, 2, 1), y = c(0, 2, 3, 0, 0))
shade_p = data.frame(t(apply(as.matrix(shade), 1, function(x) solve(P, x))))
x_mean = mean(xy_p[xy$x > 1, "x"])
y_mean = mean(xy_p[xy$x > 1, "y"])
shade_p$Selection = "Survives"

ggplot(xy_p, aes(x, y)) + geom_polygon(data = shade_p, aes(x, y), fill = "lightblue", alpha = 0.5) +
  geom_point(alpha = 0.3) + theme_bw() + coord_fixed() +
  labs(x = "Caráter x nos pais (Escala de P)", y = "Caráter y nos pais (Escala de P)") +
  geom_hline(yintercept = 0) + geom_vline(xintercept = 0) +
  geom_line(data = S_x, color = "red") + annotate("text", x = x_mean/3, y = -0.35, label = "beta[x]", size = 5, parse = T)
```

A região azul continua representando os indivíduos que sobrevivem à seleção. Mas agora a diferença nas médias antes e depois da seleção só é diferente de zero no caráter $x$ (só $x$ está sobre seleção). Essas diferenças nas médias antes e depois da seleção, medidas na escala da variância fenotípica, são chamadas de gradientes de seleção ($\beta$), e já descontam o efeito das correlações fenotípicas. Olhando para o $\beta$, que nesse caso é o vetor $\beta = [\beta_x, \beta_y] = [1.5, 0]$, sabemos que só o caráter $x$ está sofrendo seleção direcional.

Se vai haver resposta correlacionada do caráter $y$ na próxima geração depende de se os dois caracteres são correlacionados genéticamente. Um jeito de entender isso é pensar que para que haja resposta em $y$, os filhos dos pais selecionados (com $x$ acima de 1) tem que ser diferentes da média no cárater $y$. Então, a resposta depende de haver covariância entre pais e filhos para caracteres diferentes. Em condições razoáveis, a matriz de covariância genética é uma boa aproximação da covariância entre pais e filhos, e podemos prever a resposta no caráter $y$ ($\Delta z_y$) usando a matriz $G$:

$$
\Delta z_y = G_{y} \times \beta_y + G_{xy} \times \beta_{x}
$$

Ou seja, a seleção diretamente em $y$ (dada por $\beta_y$) multiplicado pela variância genética de $y$ ($G_{y}$), mais a seleção em $x$ ($\beta_x$) multiplicado pela covariância genética entre $x$ e $y$ ($G_{xy}$). No nosso exemplo, $\beta_y = 0$ e só haverá resposta evolutiva em $y$ se $G_{xy}$ for diferente de zero.

Da mesma forma, podemos escrever a resposta no caráter $x$:

$$
\Delta z_x = G_{x} \times \beta_x + G_{xy} \times \beta_{y}
$$

Podemos juntar essas duas equação numa só usando uma notação vetorial:

$$
\Delta z =
\left[
\begin{matrix}
\Delta z_x \\
\Delta z_y
\end{matrix} \right]
=
\left[
\begin{matrix}
G_x & G_{xy} \\
G_{xy} & G_y \\
\end{matrix} \right]
\left[
\begin{matrix}
\beta_x \\
\beta_y
\end{matrix} \right]
=
G\beta
$$

Essa é a equação multivariada de resposta à seleção, ou a Equação de Lande. É a equação mais cool, como podemos ver nessa foto:

```{r, out.width = "400px", echo = FALSE}
knitr::include_graphics("lande.jpg")
```

Podemos escrever a resposta à seleção em função dos diferenciais de seleção, lembrando que o gradiente de seleção é o diferencial escrito na escala da P. Nesse caso, a equação fica:

$$
\Delta z = G\beta = GP^{-1}S
$$

Comparando essa equação com a equação do criador, vemos que $GP^{-1}$ é a quantidade análoga à herdabilidade para vários caracteres.

## Estimando $\beta$

Agora que sabemos o que o $\beta$ representa e como interpretar seus valores, vamos pensar na informação que normalmente temos na natureza. Nós já estimamos as matrizes de covariância e os vetores de mudança fenotípica ($\Delta z$), como podemos usar essa informação para entender o padrão de seleção natural? Como podemos estimar o $\beta$ que teria sido responsável pela mudança fenotípica observada?

Vamos pensar no sistema de equações que escrevemos ali em cima:

$$
\begin{align}
\Delta z_x &= G_{x} \times \beta_x + G_{xy} \times \beta_{y} \\
\Delta z_y &= G_{y} \times \beta_y + G_{xy} \times \beta_{x}
\end{align}
$$

Parece bom, se sabemos a matriz G (no nosso caso usamos a P como aproximação da G), sabemos o $\Delta z$, temos duas equações e duas incognitas, podemos achar o $\beta$. No R, um sistema de equações desse tipo pode ser resolvido usando a forma matricial

$$
\Delta z = G\beta
$$

A função solve() recebe a matriz de coeficientes G e o vetor de soluções $\Delta z$, e devolve o vetor de solução $\beta$.
Por exemplo, se $\beta = [1, 2]$  e G tem variâncias iguais a 2 e covariância 1.2, o $\Delta z$ esperado é:

```{r}
beta = c(1, 2)
G = matrix(c(2, 1.2,
             1.2, 2), 2, 2)
G %*% beta
```

Então, se estamos medindo uma população, e observamos um $\Delta z = [4.4, 5.2]$ e uma matriz G com variâncias 2 e covariância 1.2, podemos calcular beta usando a equação:

$$
\begin{align}
2 \times \beta_x + 1.2 \times \beta_{y} &= 4.4\\
2 \times \beta_y + 1.2 \times \beta_{x} &= 5.2
\end{align}
$$

No R, isso seria:

```{r}
deltaZ = c(4.4, 5.2)
G = matrix(c(2, 1.2,
             1.2, 2), 2, 2)
solve(G, deltaZ)
```

Que é exatamente o $\beta$ que nós usamos no começo.

## Estimando $\beta$ nos dados

Agora vamos tentar o mesmo com algum ramo da nossa filogenia. Primeiro vamos rapidamente recalcular as médias e matrizes ancestrais:

```{r, message=FALSE, warning=FALSE}
if(!require(evolqg)){install.packages("evolqg"); library(evolqg)}
data(dentus)

# Matrizes atuais
cov_matrices = dlply(dentus, .(species), function(x) cov(x[,1:4]))

# Filogenia
if(!require(ape)){install.packages("ape"); library(ape)}
TREE <- "(A:4,(B:3,(C:2,(D:1, E:1):1):1):1);"
tree <- read.tree(text = TREE)
tree$tip.label = c("A", "B", "C", "D", "E")
tree$node.label = c("root", "BCDE", "CDE", "DE")

# Matrizes ancestrais
all_cov_matrices = PhyloW(tree, cov_matrices)
attributes(all_cov_matrices)$split_labels = attributes(all_cov_matrices)$names

# Medias atuais
dentus_means = ddply(dentus, "species", numcolwise(mean))

# Medias ancestrais
dentus_ancestral = sapply(dentus_means[2:5], function(x) ace(x, tree)$ace)
dentus_ancestral = data.frame(species = c("root", "BCDE", "CDE", "DE"), dentus_ancestral)
dentus_means_ace = rbind(dentus_means, dentus_ancestral)
all_means = dlply(dentus_means_ace, .(species), numcolwise(identity))
```

Agora vamos fazer os $\Delta z$ de uma vez só, segurem seus chapéus.

```{r}
node_names = c(tree$tip.label, tree$node.label)
node_numbers = c(1:5, 7:9)
delta_Zs = vector("list", 8)
for(i in seq(8)){
  node = node_numbers[i]
  current_node = node_names[node]
  node_mean = all_means[[current_node]]
  ancestral_node = node_names[tree$edge[tree$edge[,2] == node, 1]]
  ancestral_mean = all_means[[ancestral_node]]
  delta_Zs[[i]] = node_mean - ancestral_mean
}
names(delta_Zs) = node_names[-6]
```

Um pouco elaborado, mas bem mais fácil que fazer na mão. Agora podemos acessar o $\Delta z$ pelo nome do nó derivado. O $\Delta z$ no ramo A-root então é:

```{r}
delta_Zs$A
```

Podemos também colocar isso em forma de tabela:

```{r}
deltaZ_table = ldply(delta_Zs)
deltaZ_table
```

Ou salvar em um arquivo:

```{r}
write.csv(deltaZ_table, "meu_arquivo_de_deltaZs.csv")
```

Agora temos os $\Delta z$ e as matrizes, podemos estimar os $\beta$ ao longo da filogenia. Por exemplo, o $\beta$ no ramo C-CDE:

```{r}
beta_C_CDE = solve(all_cov_matrices$CDE, delta_Zs$C)
beta_C_CDE
```

Ou seja, aumento dos membros anteriores e diminuição dos posteriores. Vamos agora tentar entender o que esse $\beta$ significa.

## Comparação de $\Delta z$ e $\beta$

Usando a espécie C como exemplo, vamos usar a correlação de vetores para interpretar a história evolutiva dessa espécie. Primeiro vamos definir a função de correlação de vetores:

```{r}
# Vamos usar funçòes do R e do evolqg para fazer isso em uma linha
corVector = function(x, y) sum(x * y)/(Norm(x) * Norm(y))
```

Temos duas comparações importantes a serem feitas: (1) entre a mudança evolutiva e o padrão de covariação, (2) e entre a mudança evolutiva e a seleção natural. Vamos lá:

```{r}
# Auto decomposição da matriz
eigCDE = eigen(all_cov_matrices$CDE)

# Variancia explicada por cada PC:
eigCDE$values / sum(eigCDE$values) * 100

# Primeiro e segundo PCs
PC1_cde = eigCDE$vectors[,1]
PC2_cde = eigCDE$vectors[,2]

# Correlação entre PCs e deltaZ
# Nos usamos a funçao abs (valor absoluto) aqui pq o sinal de uma correlação com um PC não interessa.
# Isso pq PCs são direções e não sentidos.
abs(corVector(delta_Zs$C, PC1_cde))
abs(corVector(delta_Zs$C, PC2_cde))

# Correlação entre beta e delta Z.
# Aqui o sinal da correlação interessa
# correlações negativas indicam seleção pra um lado e resposta pro outro.
corVector(delta_Zs$C, beta_C_CDE)
```

Então, ficamos assim: correlações baixas entre $\Delta z$ e os primeiros componentes (0.07 e 0.58), mesmo eles explicando conjuntamente 75\% (52 + 23) da variação total. Isso exclui a hipótese de restrição evolutiva. Mas, quando olhamos a correlação entre seleção e resposta, temos uma correlação de 0.97, indicando que a diversificação da espécie C se deu de forma alinhada com a seleção (e não seguindo a linha de menor resistência, como vimos com a correlação de 0.07 com o PC1). Sabemos também que a seleção foi para aumentar os membros anteriores e diminuir os posteriores. Será que o habito de vida dessa espécie pode trazer alguma pista?

Agora, faça essa análise para todas as espécies e nós internos.

